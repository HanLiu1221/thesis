
% Thesis Introduction File

\chapter{Introduction}

A variety of modeling tools (e.g., Maya, SketchUp, etc) have been developed to ease the creation of 3D contents in past decades. Creating from scratch, however, is still challenging for novice users since it requires professional skills or time-consuming training as well as the creativity. With the expansion of online repositories of 3D models, synthesizing new models from existing ones has been widely studied~\cite{MitraSTAR2013} especially for man-made objects in recent years. Another trend is to explain 2D sketches with 3D forms by either referring to the given context or abstracting free-hand drawings under certain constraints\cite{Olsen2009}. In this dissertation, we introduce our work in supporting design from varying input shapes to interpreting 2D sketches with three instantiations.

\section{Graph-based shape abstraction}

Part-based modeling is a popular choice for analyzing rules of shape composition. Combination rules can be derived from the decomposition of models, suggesting how a new shape is created by recombing necessary segments. The procedure usually involves segmenting models into disjoint parts, inducing relational rules and re-assembling shape parts. Graph can naturally depict inner relations of shape segments by taking shape components as nodes and component relations as edges~\cite{Zheng:2013}. The graph representation is frequently used in analyzing shape structures, as well as guiding shape synthesis~\cite{topoVarying14}. A graph is built by segmenting an input model and labeling the relations between the segments.As shown in Figure~\ref{fig:intro_shape_graph}, a chair is simply decomposed to three semantic parts, seat, back and legs. Symmetry relation indicate the two components share the same features, thereby will be edited simultaneously. In our work, we consider just the contact relations.

\begin{figure}[t!]
  \includegraphics[width=\columnwidth]{./images/introduction/shape_graph.pdf}
  \caption{An example of shape graph. The nodes denote segments of the chair model by corresponding colors while edges denote the relations between segments.}
  \label{fig:intro_shape_graph}
\end{figure}

\subsection{Model segmentation}

Model segmentation is an underlying problem in shape analysis. A number of unsupervised and supervised methods for mesh segmentation have been proposed for detecting part boundaries~\cite{Sidi11,Wang12} and summarized in the survey~\cite{shamir2008survey}. However, fully automatic segmentation still remains a hard problem especially for semantic partitions. For example, a model with self repetitions like building facades needs detail preserved segmentation, while a mechanical model such as an excavator requires a coarse but functional decomposition. As our work focuses on creating models from a small group of shapes, we use manual segmentation by simply grouping mesh parts. Previous work like modeling by example~\cite{Funkhouser2004}, pioneered in part based modeling, let users cut a model by simply painting on the mesh. ShapeAnnotator~\cite{attene:09} proposed to annotate a surface mesh with semantics. In our work, we provide an interactive tool to select a group of components by mouse dragging and then mark it a type of shape part by assigning a color index.

\subsection{Inner relations between shape components}

How shape parts connect to each other is the key to re-assemble shape components. An intuitive relation is the connectivity of parts. In a higher level, it can be an specific feature of some similar parts such as repetition, or pairwise correlations like orthogonality and coplanarity. The iWires system~\cite{Gal2009} introduced structure-aware editing which inspired subsequent works on preserving structural relations of shape components. The identified relations between shape parts (e.g., parallel, orthogonal, symmetry, etc) are used to guide the generation of valid models that preserve such relations. We use the graph representation for each shape, where specific relations can be assigned to the edges. Graph operations are then defined towards node connections, based on which the validity of new graphs can be evaluated. Instead of defining featured edges like symmetry in Figure~\ref{fig:intro_shape_graph}, our work relies only on the topological relations, i.e., contacts. From a set of input models and abstracted graph representations, we learn the connection rules among shape parts, and further search equivalent substructures across models. A variety of shapes can then be created by replacing such substructures.

\section{Functional constraints of man-made objects}

Shape variations can differ in both geometry and topology. The form is usually performed by deformation or part(s) to part(s) replacement. The latter is usually implemented under certain constraints such as the functionality or physical attributes~\cite{mitra_howThingsWork_sig_10,Zheng:2013}. Based on human perception, functions can be extracted from part connections such as supporting if one component underlies the other components. In addition, global constraints of a model usually involve a validation check. For example, to create a valid floor plan, reasonable room space has to be guaranteed, as well as unblocked paths that can lead to each room from the entry. Another example is the design of furniture, the ground touching parts have to be stable for supporting the whole structure.

\subsection{Local constraint}

Local constraints enforce geometric plausibility at a local level, that is, the neighborhoods of a synthesized shape must look plausible, regardless of the overall shape. The constraints are usually formulated as geometric similarity of all local neighborhoods to portions of the example data. In the context of part-based modeling, this constrains the connections between parts, as exemplified in the input, such as the contact between a table top and table legs. In part-based modeling, parts with the same semantic label are replaceable by all means. However, such parts may vary in appearance, quantity and even the way to assemble. Considering different topologies, the replaceable substructures have to be extended to a group of shape parts behaving similarly.


\subsection{Global constraint}

The global constraints are key to classify different families of shapes, which describe non-local correlations in part usage. An early understanding of shape functionality is the upright orientation of objects~\cite{Fu2008}. Then, Zheng et al.~\cite{Zheng:2013} proposed symmetric functional arrangement of man-made objects and studied three types of the arrangement, i.e., support, embed, and placement. In fact, such functionalities can be abstracted in a higher level by interacting with humans, known as ergonomics. Ergonomics factors are encoded in the furniture arragement~\cite{yu2011make} for interior layout generation. The Shape2Pose system\cite{Kim:2014:SHS} analyzed the contact relations between human body and shapes to predict poses for given models. In a related work ~\cite{zldm_ergonomics_tvcg15}, we abstracted ergonomics guidelines and associated it with shape constraints. Take a chair for example, the height of the chair seat has to allow both feet supported by ground, while the width and the depth should conform to human's dimensions. Therefore, the length of chair legs binds with the length of human legs, and the width of chair seat binds with waistlines. Such constraints can be easily adapted to other models like bikes and gym equipments.

In this dissertation, we consider both the local consistency and global functionality of shapes. Replaceable substructures are discovered in a single shape or across different shapes, the boundaries of which have to be matched to enable interchangeable topologies. We then extend our method to take into account global constraints as well. In our current implementation, we examine a small set of representative examples such as topological constraints to ensure routes between entry-exit points, geometric constraints to ensure stability and functional validity of models. When performing modeling from sketches, new content is established based on both their inner relations and their connections with existing structures to attain a global optimized model.

\section{Designing models}

Creating a large set of shape variations from a small input set is useful in both virtual scenes setup and real world like design. We focus on structural models and apply shape graphs to interior layout design, part-based modeling, and sketching 3D context.


\subsection{Interior layout design}

The design of interior layout is to arrange input rooms in a given envelope or to approximate space area under the scale and connectivity constraints. The input includes certain user requirements like room sizes and relations. There can also be accessibility considerations, for example, a bathroom is preferably attached to the main bedroom; the dining room should be next to the kitchen. Furthermore, as a sanity measure, all the rooms should be accessible by connected paths from the main door. In the case of multi-storied buildings, there are additional constraints, e.g., the position and the dimensions of stairs have to match across different floors.

In our setup, the user first indicates global functional specializations by prescribing approximate area of each room and a connectivity graph indicating the desired inter-room connections. Subsequently, the system returns realizations conforming to the input constraints. Even when such a layout satisfies all the predefined conditions, users may still want to tune the design, such as changing room areas or swapping pairs of rooms. More importantly, being oblivious to the final construction, the user designed floor plan may be ill-suited to the actual manufacturing process, and thus be expensive. Hence, besides ensuring functional floor plan when the user manipulates any suggested design, we specially optimize the geometric realization to produce economic constructions. Thus, both functional and fabrication constraints are considered in our proposed interactive design system.

\subsection{Part-based modeling}

In part-based modeling, an intuitive approach to generate new models is to switch those corresponding parts. Besides of one-to-one replacement, reshuffling similar substructures produce more variations with topology changes. In addition to preserving geometry consistency of synthesized shapes, we also integrate simple global constraints to examine the validity of results.

We start by building a theoretical framework for part-based shape modeling, describing models as shape graphs and reducing consistency conditions as pairwise constraints corresponding to the formal construct of a tiling grammar. As a negative result, we show that such a modeling problem is undecidable and even restricted variants, e.g., shape synthesis with limited number of pieces, is NP-hard. We propose a suitable restriction of the search space that trades-off some variability for efficiency. Rather than synthesizing new shapes from scratch, the algorithm enumerates all possible replacements of subgraphs of an existing shape graph, which, surprisingly, can be achieved in low-order polynomial time under mild restrictions. Specifically, we obtain an algorithm with quadratic time complexity in two steps: (i) We assume a local ordering of outgoing edges in each node, which is trivial for manifold models. (ii) We factor out an exponential overhead of redundant solutions with equivalent effect. We improve practical performance further by working with the dual of the original shape graphs to encodes inter-part connectivity. Here, the large class of candidate variations considered at once by our approach permits a more efficient discovery of solutions than a naive part-by-part assembly strategy.

\subsection{Sketching 3D context}

Users are restricted in interacting the design process at a high level, as described in the previous modeling step. Models are already shaped in an initial stage and presented to users, i.e., a floor plan, and input shape space. Professional users like artists and designers favor sketching out their ideas, e.g., plans for a house, the layout of a plaza, a set design for the theater, or placement of a new bridge. Sketching is fast, fluid, and iterative. Although sketch is guided by imagination, it is also referential when set in space, or when building on some previous idea or design. Naturally, when a sketch is made to record an observation, it is by definition tied to a physical setting~\cite{NecessityDrawing77}. Therefore, as the artist or designer draws and redraws, she not only refines the object, she also explores the physical setting in which the object or design will be placed.

Traditional sketch on paper is limited to a single viewpoint. The missing 3D information hinders exploration of the scene under different views or perspective perturbations, or selectively moving around objects, or conceptualizing larger design modifications.  When the designer re-sketches to explore another view, unfortunately she cannot use or reference previous drawings. Transforming such sketches to 3D is difficult. The sketched scenes are largely virtual and hence common vision-based reconstructions are not directly applicable; the sketches are rough, incomplete, and only indicative of the actual 3D curves, i.e., they lack any depth information; and often the sketches are from single viewpoints. If the designer chooses to design from the start in 3D using available or specialized CAD modeling tools, she is committed to a more restrictive, time-consuming and tedious approach that requires exact specifications and details from the start of the process. This invariably inhibits, rather than expands, the scope of exploration~\cite{sketchBook:11}. In effect, the designer trades some measure of artistic spontaneity and freedom for the precision of CAD software.

We observe that many architectural and industrial design settings are man-made scenes with primarily regular objects. Such objects are either mutually well-aligned, or near-regularly arranged. Hence, their embedding planes provide rich context that can be leveraged to interpret user strokes. We present an interactive design abstraction tool for the artists. To begin, given a single image or sketch, the user calibrates the scene by annotating a few lines. As the user continues to sketch, our system automatically partitions the sketched lines, groups them, and guesses their intersection pattern. Once finished, she can either approve the grouping and intersection suggestions, or manually override them. Then, in the key step, our system simultaneously lifts all the sketched curves to 3D via a novel context-guided labeling formulation. Intuitively, by assuming the user strokes to be planar, we can simultaneously assign embedding planes for all the strokes that lead to a regular arrangement in space. Technically, the existing context is used to create initial candidate planes for the above labeling. Surprisingly, this provides enough regularization to extract a good scene abstraction. The process continues with the inferred abstraction providing enriched context for subsequent sketch interpretation. Thus, as the scene context gets progressively enriched, sketch interpretation gets simpler. The extracted abstraction can then be used as billboard proxies for view perturbations and  inspection for subsequent design modifications.

\begin{figure}[t!]
  \includegraphics[width=\columnwidth]{./images/introduction/sketch_graph.pdf}
  \caption{An example of 2D sketch (a). The crosses denote graph edges that connect the user strokes (nodes) indicated by different colors (b), and the resulted 3D model (c).}
  \label{fig:intro_sketch_graph}
\end{figure}

\section{Contributions}

In this dissertation, we present efficient modeling solutions using graph representations. In part-based modeling, graph edges represent the topological connections of shape parts, from which we apply the extracted connection rules to create new shapes. In a further implementation, we abstract 3D forms of user sketches in 2D. The graph edges then denote the connections between strokes (see Figure~\ref{fig:intro_sketch_graph}(b)), from which we formulate a selection optimization to find out the arrangement of canvases/planes hosting strokes (Figure~\ref{fig:intro_sketch_graph}(c)).

%\subsection{Formulating manufactural constraints}
\mypara{Formulating manufactural constraints}
Based on existing techniques of automatic layout generation, we introduce a fabrication-aware approach to reshape floor plans. Starting from an initialization of room layout according to input requirements, users are allowed to interact with the suggested layout. Our interface adaptively optimizes the global arrangement of rooms under geometric and fabrication constraints. Specifically, we focus on precast concrete based buildings with the aim to save construction cost by reducing the number of cuts on slabs. The global optimization is followed by a reshaping that calculates the best usage of concrete slabs for the entire building.

%\subsection{Fast subgraph search during progressive editing}
\mypara{Efficient subgraph search}
We formulate a theoretical framework for part-based shape modeling. We analyze the NP-hard synthesis problem and propose a polynomial time algorithm. As the main algorithmic contribution, we describe a novel algorithm that efficiently enumerates all replaceable substructures that lead to shape modification operations. With the shape graph representation, we learn the docking rules and search for replaceable substructures with local consistency. The search are implemented in one or multiple models, as long as a pair of substructure can be found, where the boundaries match exactly while the interior can be ignored. By switching or replacing subregions, new models are iteratively produced and used for the next generation of analysis and synthesis. We also introduce several simple global constraints for evaluating the functionality of shape variations.

%\subsection{Inferring 3D canvases for 2D sketches}
\mypara{Inferring 3D canvases for 2D sketches}
We propose a sketching system that approximates 3D canvases of user strokes. Taking an arbitrary image (e.g., natural scene, street view, etc) as the canvas, we first prepare the sketch space by calibrating the camera and inform the user of the perspective respecting the background image. When the user sketches, our system performs a background analysis on the strokes by automatic segmentation and grouping, following by solving a selection problem for context-inferred canvas planes. We test the usability of our system by a user study and collect the sketching results from designers, artists and students with computer graphics background.

\section{Thesis layout}

This thesis is organized as follows. Chapter 2 is a literature study on related work towards three aspects: $i$) interior layout creation, $ii$) shape analysis and synthesis, and $iii$) inferring the 3D context from 2D sketches. The following chapters introduce our work on 2D and 3D graph operations, demonstrated by three instantiations. Chapter 3 presents the layout generation from a 2D design graph, satisfying a set of constraints including fabrication considerations. Chapter 4 explores 3D shape graph to create shape variations from a single model or a group of similar models. Chapter 5 reconstruct 3D canvases for user sketches in a given context or free-hand drawing by analyzing coplanar strokes, along with system performance and user evaluation. We then conclude with a discussion of the current and future work in chapter~\ref{chapter:conclusion}.
